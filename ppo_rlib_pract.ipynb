{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pathlib\n",
    "\n",
    "import sumo_rl\n",
    "from sumo_rl.environment.env import env, parallel_env, SumoEnvironment\n",
    "\n",
    "import ray\n",
    "\n",
    "from ray.tune import register_env\n",
    "from ray.rllib.env import PettingZooEnv, ParallelPettingZooEnv\n",
    "from ray.rllib.algorithms import ppo \n",
    "from ray.rllib.env.wrappers.multi_agent_env_compatibility import MultiAgentEnvCompatibility\n",
    "\n",
    "from environment.envs import RealMultiAgentSumoEnv\n",
    "from environment.observation import Grid2x2ObservationFunction, EntireObservationFunction\n",
    "from environment.reward_functions import combined_reward\n",
    "\n",
    "from pettingzoo.utils import wrappers\n",
    "\n",
    "os.environ[\"PYTHONWARNINGS\"] = 'ignore::DeprecationWarning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retrying in 1 seconds\n",
      "Step #0.00 (0ms ?*RT. ?UPS, TraCI: 16ms, vehicles TOT 0 ACT 0 BUF 0)                     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/loveen/.pyenv/versions/3.9.10/lib/python3.9/site-packages/pettingzoo/utils/conversions.py:132: UserWarning: The base environment `sumo_rl_v0` does not have a `render_mode` defined.\n",
      "  warnings.warn(\n",
      "2024-02-18 08:27:15,598\tINFO worker.py:1673 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retrying in 1 seconds\n",
      "Step #0.00 (0ms ?*RT. ?UPS, TraCI: 14ms, vehicles TOT 0 ACT 0 BUF 0)                     \n",
      " Retrying in 1 seconds\n"
     ]
    }
   ],
   "source": [
    "os.environ['SUMO_HOME'] = '/opt/homebrew/opt/sumo/share/sumo'\n",
    "os.environ['RAY_PICKLE_VERBOSE_DEBUG'] = '1'\n",
    "\n",
    "env_folder = \"data/2x2grid\"\n",
    "\n",
    "env_name = \"2x2grid\"\n",
    "\n",
    "multi_agent_env = parallel_env(    \n",
    "        net_file = os.path.join(env_folder, \"2x2.net.xml\"),\n",
    "        route_file = os.path.join(env_folder, \"2x2.rou.xml\"),\n",
    "        reward_fn = combined_reward,\n",
    "        observation_class = EntireObservationFunction, \n",
    "        out_csv_name=\"outputs/2x2grid/ppo\", \n",
    "        num_seconds=1000000,\n",
    "        add_per_agent_info=True,\n",
    "        add_system_info=True,\n",
    "        single_agent=False)\n",
    "\n",
    "seed = 4\n",
    "\n",
    "env_params = {\"net_file\": os.path.join(env_folder, \"2x2.net.xml\"),\n",
    "        \"route_file\": os.path.join(env_folder, \"2x2.rou.xml\"),\n",
    "        \"reward_fn\": combined_reward,\n",
    "        \"observation_class\": EntireObservationFunction, \n",
    "        \"out_csv_name\": \"outputs/2x2grid/ppo\", \n",
    "        \"num_seconds\": 1000,\n",
    "        \"add_per_agent_info\": True,\n",
    "        \"add_system_info\": True,\n",
    "        \"sumo_seed\": seed,\n",
    "        \"single_agent\": False}\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init()\n",
    "\n",
    "# ValueError: Env must be of one of the following supported types: \n",
    "# BaseEnv, gymnasium.Env, gym.Env, MultiAgentEnv, VectorEnv, RemoteBaseEnv, ExternalMultiAgentEnv, \n",
    "# ExternalEnv, but instead is of type <class 'environment.envs.RealMultiAgentSumoEnv'>.\n",
    "\n",
    "multi_agent_par_env = RealMultiAgentSumoEnv(**env_params) # SUMO environment implementing PettingZoo API TODO: CHANGE NAME\n",
    "\n",
    "rllib_compat_ppz_env_aecrllib_compat_ppz_env = ParallelPettingZooEnv(multi_agent_par_env) # Wrap it to be a Parallel Petting Zoo env \n",
    "\n",
    "rllib_compat_env = MultiAgentEnvCompatibility(rllib_compat_ppz_env) # convert from old api to new \n",
    "\n",
    "register_env(name=env_name, env_creator= lambda config : rllib_compat_env) # register env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Traceback (most recent call last):\n  File \"/Users/loveen/.pyenv/versions/3.9.10/lib/python3.9/site-packages/ray/rllib/utils/pre_checks/env.py\", line 307, in check_multiagent_environments\n    obs_and_infos = env.reset(seed=42, options={})\n  File \"/Users/loveen/.pyenv/versions/3.9.10/lib/python3.9/site-packages/ray/rllib/env/wrappers/multi_agent_env_compatibility.py\", line 46, in reset\n    self.env.seed(seed)\nAttributeError: 'ParallelPettingZooEnv' object has no attribute 'seed'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/loveen/.pyenv/versions/3.9.10/lib/python3.9/site-packages/ray/rllib/utils/pre_checks/env.py\", line 81, in check_env\n    check_multiagent_environments(env)\n  File \"/Users/loveen/.pyenv/versions/3.9.10/lib/python3.9/site-packages/ray/rllib/utils/pre_checks/env.py\", line 312, in check_multiagent_environments\n    raise ValueError(\nValueError: Your environment (<MultiAgentEnvCompatibility instance>) does not abide to the new gymnasium-style API!\nFrom Ray 2.3 on, RLlib only supports the new (gym>=0.26 or gymnasium) Env APIs.\nIn particular, the `reset()` method seems to be faulty.\nLearn more about the most important changes here:\nhttps://github.com/openai/gym and here: https://github.com/Farama-Foundation/Gymnasium\n\nIn order to fix this problem, do the following:\n\n1) Run `pip install gymnasium` on your command line.\n2) Change all your import statements in your code from\n   `import gym` -> `import gymnasium as gym` OR\n   `from gym.space import Discrete` -> `from gymnasium.spaces import Discrete`\n\nFor your custom (single agent) gym.Env classes:\n3.1) Either wrap your old Env class via the provided `from gymnasium.wrappers import\n     EnvCompatibility` wrapper class.\n3.2) Alternatively to 3.1:\n - Change your `reset()` method to have the call signature 'def reset(self, *,\n   seed=None, options=None)'\n - Return an additional info dict (empty dict should be fine) from your `reset()`\n   method.\n - Return an additional `truncated` flag from your `step()` method (between `done` and\n   `info`). This flag should indicate, whether the episode was terminated prematurely\n   due to some time constraint or other kind of horizon setting.\n\nFor your custom RLlib `MultiAgentEnv` classes:\n4.1) Either wrap your old MultiAgentEnv via the provided\n     `from ray.rllib.env.wrappers.multi_agent_env_compatibility import\n     MultiAgentEnvCompatibility` wrapper class.\n4.2) Alternatively to 4.1:\n - Change your `reset()` method to have the call signature\n   'def reset(self, *, seed=None, options=None)'\n - Return an additional per-agent info dict (empty dict should be fine) from your\n   `reset()` method.\n - Rename `dones` into `terminateds` and only set this to True, if the episode is really\n   done (as opposed to has been terminated prematurely due to some horizon/time-limit\n   setting).\n - Return an additional `truncateds` per-agent dictionary flag from your `step()`\n   method, including the `__all__` key (100% analogous to your `dones/terminateds`\n   per-agent dict).\n   Return this new `truncateds` dict between `dones/terminateds` and `infos`. This\n   flag should indicate, whether the episode (for some agent or all agents) was\n   terminated prematurely due to some time constraint or other kind of horizon setting.\n\n\nThe above error has been found in your environment! We've added a module for checking your custom environments. It may cause your experiment to fail if your environment is not set up correctly. You can disable this behavior via calling `config.environment(disable_env_checking=True)`. You can run the environment checking module standalone by calling ray.rllib.utils.check_env([your env]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/lib/python3.9/site-packages/ray/rllib/utils/pre_checks/env.py:307\u001b[0m, in \u001b[0;36mcheck_multiagent_environments\u001b[0;34m(env)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 307\u001b[0m     obs_and_infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;66;03m# No more gym < 0.26 support! Error and explain the user how to upgrade to\u001b[39;00m\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;66;03m# gymnasium.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/lib/python3.9/site-packages/ray/rllib/env/wrappers/multi_agent_env_compatibility.py:46\u001b[0m, in \u001b[0;36mMultiAgentEnvCompatibility.reset\u001b[0;34m(self, seed, options)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m seed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed\u001b[49m(seed)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Options are ignored\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ParallelPettingZooEnv' object has no attribute 'seed'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/lib/python3.9/site-packages/ray/rllib/utils/pre_checks/env.py:81\u001b[0m, in \u001b[0;36mcheck_env\u001b[0;34m(env, config)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(env, MultiAgentEnv):\n\u001b[0;32m---> 81\u001b[0m     \u001b[43mcheck_multiagent_environments\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(env, VectorEnv):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/lib/python3.9/site-packages/ray/rllib/utils/pre_checks/env.py:312\u001b[0m, in \u001b[0;36mcheck_multiagent_environments\u001b[0;34m(env)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    313\u001b[0m         ERR_MSG_OLD_GYM_API\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    314\u001b[0m             env, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn particular, the `reset()` method seems to be faulty.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    315\u001b[0m         )\n\u001b[1;32m    316\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    317\u001b[0m reset_obs, reset_infos \u001b[38;5;241m=\u001b[39m obs_and_infos\n",
      "\u001b[0;31mValueError\u001b[0m: Your environment (<MultiAgentEnvCompatibility instance>) does not abide to the new gymnasium-style API!\nFrom Ray 2.3 on, RLlib only supports the new (gym>=0.26 or gymnasium) Env APIs.\nIn particular, the `reset()` method seems to be faulty.\nLearn more about the most important changes here:\nhttps://github.com/openai/gym and here: https://github.com/Farama-Foundation/Gymnasium\n\nIn order to fix this problem, do the following:\n\n1) Run `pip install gymnasium` on your command line.\n2) Change all your import statements in your code from\n   `import gym` -> `import gymnasium as gym` OR\n   `from gym.space import Discrete` -> `from gymnasium.spaces import Discrete`\n\nFor your custom (single agent) gym.Env classes:\n3.1) Either wrap your old Env class via the provided `from gymnasium.wrappers import\n     EnvCompatibility` wrapper class.\n3.2) Alternatively to 3.1:\n - Change your `reset()` method to have the call signature 'def reset(self, *,\n   seed=None, options=None)'\n - Return an additional info dict (empty dict should be fine) from your `reset()`\n   method.\n - Return an additional `truncated` flag from your `step()` method (between `done` and\n   `info`). This flag should indicate, whether the episode was terminated prematurely\n   due to some time constraint or other kind of horizon setting.\n\nFor your custom RLlib `MultiAgentEnv` classes:\n4.1) Either wrap your old MultiAgentEnv via the provided\n     `from ray.rllib.env.wrappers.multi_agent_env_compatibility import\n     MultiAgentEnvCompatibility` wrapper class.\n4.2) Alternatively to 4.1:\n - Change your `reset()` method to have the call signature\n   'def reset(self, *, seed=None, options=None)'\n - Return an additional per-agent info dict (empty dict should be fine) from your\n   `reset()` method.\n - Rename `dones` into `terminateds` and only set this to True, if the episode is really\n   done (as opposed to has been terminated prematurely due to some horizon/time-limit\n   setting).\n - Return an additional `truncateds` per-agent dictionary flag from your `step()`\n   method, including the `__all__` key (100% analogous to your `dones/terminateds`\n   per-agent dict).\n   Return this new `truncateds` dict between `dones/terminateds` and `infos`. This\n   flag should indicate, whether the episode (for some agent or all agents) was\n   terminated prematurely due to some time constraint or other kind of horizon setting.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrllib_compat_env\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/lib/python3.9/site-packages/ray/rllib/utils/pre_checks/env.py:96\u001b[0m, in \u001b[0;36mcheck_env\u001b[0;34m(env, config)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m     actual_error \u001b[38;5;241m=\u001b[39m traceback\u001b[38;5;241m.\u001b[39mformat_exc()\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mactual_error\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe above error has been found in your environment! \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mve added a module for checking your custom environments. It \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmay cause your experiment to fail if your environment is not set up \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorrectly. You can disable this behavior via calling `config.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menvironment(disable_env_checking=True)`. You can run the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    103\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menvironment checking module standalone by calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mray.rllib.utils.check_env([your env]).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    105\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Traceback (most recent call last):\n  File \"/Users/loveen/.pyenv/versions/3.9.10/lib/python3.9/site-packages/ray/rllib/utils/pre_checks/env.py\", line 307, in check_multiagent_environments\n    obs_and_infos = env.reset(seed=42, options={})\n  File \"/Users/loveen/.pyenv/versions/3.9.10/lib/python3.9/site-packages/ray/rllib/env/wrappers/multi_agent_env_compatibility.py\", line 46, in reset\n    self.env.seed(seed)\nAttributeError: 'ParallelPettingZooEnv' object has no attribute 'seed'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/loveen/.pyenv/versions/3.9.10/lib/python3.9/site-packages/ray/rllib/utils/pre_checks/env.py\", line 81, in check_env\n    check_multiagent_environments(env)\n  File \"/Users/loveen/.pyenv/versions/3.9.10/lib/python3.9/site-packages/ray/rllib/utils/pre_checks/env.py\", line 312, in check_multiagent_environments\n    raise ValueError(\nValueError: Your environment (<MultiAgentEnvCompatibility instance>) does not abide to the new gymnasium-style API!\nFrom Ray 2.3 on, RLlib only supports the new (gym>=0.26 or gymnasium) Env APIs.\nIn particular, the `reset()` method seems to be faulty.\nLearn more about the most important changes here:\nhttps://github.com/openai/gym and here: https://github.com/Farama-Foundation/Gymnasium\n\nIn order to fix this problem, do the following:\n\n1) Run `pip install gymnasium` on your command line.\n2) Change all your import statements in your code from\n   `import gym` -> `import gymnasium as gym` OR\n   `from gym.space import Discrete` -> `from gymnasium.spaces import Discrete`\n\nFor your custom (single agent) gym.Env classes:\n3.1) Either wrap your old Env class via the provided `from gymnasium.wrappers import\n     EnvCompatibility` wrapper class.\n3.2) Alternatively to 3.1:\n - Change your `reset()` method to have the call signature 'def reset(self, *,\n   seed=None, options=None)'\n - Return an additional info dict (empty dict should be fine) from your `reset()`\n   method.\n - Return an additional `truncated` flag from your `step()` method (between `done` and\n   `info`). This flag should indicate, whether the episode was terminated prematurely\n   due to some time constraint or other kind of horizon setting.\n\nFor your custom RLlib `MultiAgentEnv` classes:\n4.1) Either wrap your old MultiAgentEnv via the provided\n     `from ray.rllib.env.wrappers.multi_agent_env_compatibility import\n     MultiAgentEnvCompatibility` wrapper class.\n4.2) Alternatively to 4.1:\n - Change your `reset()` method to have the call signature\n   'def reset(self, *, seed=None, options=None)'\n - Return an additional per-agent info dict (empty dict should be fine) from your\n   `reset()` method.\n - Rename `dones` into `terminateds` and only set this to True, if the episode is really\n   done (as opposed to has been terminated prematurely due to some horizon/time-limit\n   setting).\n - Return an additional `truncateds` per-agent dictionary flag from your `step()`\n   method, including the `__all__` key (100% analogous to your `dones/terminateds`\n   per-agent dict).\n   Return this new `truncateds` dict between `dones/terminateds` and `infos`. This\n   flag should indicate, whether the episode (for some agent or all agents) was\n   terminated prematurely due to some time constraint or other kind of horizon setting.\n\n\nThe above error has been found in your environment! We've added a module for checking your custom environments. It may cause your experiment to fail if your environment is not set up correctly. You can disable this behavior via calling `config.environment(disable_env_checking=True)`. You can run the environment checking module standalone by calling ray.rllib.utils.check_env([your env])."
     ]
    }
   ],
   "source": [
    "ray.rllib.utils.check_env(rllib_compat_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retrying in 1 seconds\n",
      "Step #0.00 (0ms ?*RT. ?UPS, TraCI: 11ms, vehicles TOT 0 ACT 0 BUF 0)                     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/loveen/.pyenv/versions/3.9.10/lib/python3.9/site-packages/ray/rllib/algorithms/algorithm.py:484: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/Users/loveen/.pyenv/versions/3.9.10/lib/python3.9/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/Users/loveen/.pyenv/versions/3.9.10/lib/python3.9/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/Users/loveen/.pyenv/versions/3.9.10/lib/python3.9/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RolloutWorker pid=93203)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[36m(RolloutWorker pid=93202)\u001b[0m Step #0.00 (0ms ?*RT. ?UPS, TraCI: 14ms, vehicles TOT 0 ACT 0 BUF 0)                     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RolloutWorker pid=93202)\u001b[0m 2024-02-14 10:44:29,338\tWARNING __init__.py:10 -- PG has/have been moved to `rllib_contrib` and will no longer be maintained by the RLlib team. You can still use it/them normally inside RLlib util Ray 2.8, but from Ray 2.9 on, all `rllib_contrib` algorithms will no longer be part of the core repo, and will therefore have to be installed separately with pinned dependencies for e.g. ray[rllib] and other packages! See https://github.com/ray-project/ray/tree/master/rllib_contrib#rllib-contrib for more information on the RLlib contrib effort.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RolloutWorker pid=92364)\u001b[0m Error: tcpip::Socket::recvAndCheck @ recv: peer shutdown\n",
      "\u001b[36m(RolloutWorker pid=92364)\u001b[0m Quitting (on error).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RolloutWorker pid=92364)\u001b[0m Step #0.00\n"
     ]
    }
   ],
   "source": [
    "config = (ppo.PPOConfig()\n",
    "        .environment(env_name))\n",
    "\n",
    "algo = config.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retrying in 1 seconds\n",
      "Step #0.00 (0ms ?*RT. ?UPS, TraCI: 8ms, vehicles TOT 0 ACT 0 BUF 0)                      \n",
      " Retrying in 1 seconds\n",
      "Step #0.00 (0ms ?*RT. ?UPS, TraCI: 51ms, vehicles TOT 0 ACT 0 BUF 0)                     \n",
      " Retrying in 1 seconds\n"
     ]
    }
   ],
   "source": [
    "multi_agent_par_env = RealMultiAgentSumoEnv(**env_params) # SUMO environment implementing PettingZoo API TODO: CHANGE NAME\n",
    "\n",
    "rllib_compat_ppz_env_aec = PettingZooEnv(multi_agent_par_env) # Wrap it to be a Petting Zoo env \n",
    "\n",
    "ray.rllib.utils.check_env(rllib_compat_ppz_env_aec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pettingzoo.utils.conversions import aec_to_parallel_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retrying in 1 seconds\n",
      "Step #0.00 (0ms ?*RT. ?UPS, TraCI: 17ms, vehicles TOT 0 ACT 0 BUF 0)                     \n",
      " Retrying in 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/loveen/.pyenv/versions/3.9.10/lib/python3.9/site-packages/pettingzoo/utils/conversions.py:132: UserWarning: The base environment `sumo_rl_v0` does not have a `render_mode` defined.\n",
      "  warnings.warn(\n",
      "/Users/loveen/.pyenv/versions/3.9.10/lib/python3.9/site-packages/pettingzoo/utils/conversions.py:144: UserWarning: The `observation_spaces` dictionary is deprecated. Use the `observation_space` function instead.\n",
      "  warnings.warn(\n",
      "/Users/loveen/.pyenv/versions/3.9.10/lib/python3.9/site-packages/pettingzoo/utils/conversions.py:158: UserWarning: The `action_spaces` dictionary is deprecated. Use the `action_space` function instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #0.00 (0ms ?*RT. ?UPS, TraCI: 42ms, vehicles TOT 0 ACT 0 BUF 0)                     \n",
      " Retrying in 1 seconds\n"
     ]
    }
   ],
   "source": [
    "multi_agent_aec_pz_env = RealMultiAgentSumoEnv(**env_params) # my own subclass inheriting from SumoEnvironmentPZ (a class that implements PettingZoo API)\n",
    "\n",
    "multi_agent_aec_pz_env_asserted = wrappers.AssertOutOfBoundsWrapper(multi_agent_aec_pz_env)\n",
    "multi_agent_aec_pz_env_order_enfor = wrappers.OrderEnforcingWrapper(multi_agent_aec_pz_env_asserted)\n",
    "\n",
    "multi_agent_par_env_order_enfor_par = aec_to_parallel_wrapper(multi_agent_aec_pz_env_order_enfor)\n",
    "\n",
    "rllib_compat_ppz_env_par = ParallelPettingZooEnv(multi_agent_par_env_order_enfor_par) # Wrap it to be a Parallel Petting Zoo env \n",
    "\n",
    "ray.rllib.utils.check_env(rllib_compat_ppz_env_par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rllib_compat_env = MultiAgentEnvCompatibility(rllib_compat_ppz_env) # convert from old api to new \n",
    "\n",
    "# env = wrappers.AssertOutOfBoundsWrapper(env)\n",
    "# env = wrappers.OrderEnforcingWrapper(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (lambda agent_id, *args, **kwargs: agent_id)\n",
    "b = (lambda agent_id, **kwargs: agent_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a(3, 8, k=8, j=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamda_func = (lambda integ : 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lamda_func(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
