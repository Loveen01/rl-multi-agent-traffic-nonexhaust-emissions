{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pathlib\n",
    "\n",
    "import traci\n",
    "import sumo_rl\n",
    "from pettingzoo.utils.conversions import parallel_wrapper_fn\n",
    "from environment.reward_functions import combined_reward\n",
    "\n",
    "from environment.observation import Grid2x2ObservationFunction\n",
    "\n",
    "os.environ['SUMO_HOME'] = '/opt/homebrew/opt/sumo/share/sumo'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create parallel environment API using SUMO-RL + rllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sumo_rl.environment.env import env, parallel_env\n",
    "from ray.tune import register_env\n",
    "from ray.rllib.env.wrappers.pettingzoo_env import ParallelPettingZooEnv\n",
    "from ray.rllib.env.wrappers.multi_agent_env_compatibility import MultiAgentEnvCompatibility\n",
    "\n",
    "from environment.envs import multi_agent_env\n",
    "\n",
    "env_folder = \"data/2x2grid\"\n",
    "\n",
    "multi_agent_env = parallel_env(    \n",
    "        net_file = os.path.join(env_folder, \"2x2.net.xml\"),\n",
    "        route_file = os.path.join(env_folder, \"2x2.rou.xml\"),\n",
    "        reward_fn = combined_reward,\n",
    "        observation_class = Grid2x2ObservationFunction, \n",
    "        out_csv_name=\"outputs/2x2grid/ppo\", \n",
    "        num_seconds=1000,\n",
    "        add_per_agent_info=True,\n",
    "        add_system_info=True)\n",
    "\n",
    "parallel_petting_env = ParallelPettingZooEnv(multi_agent_env)   # ParallelPettingZoo is a wrapper from rrlib, \n",
    "                                                                # that wraps an env into rrlib compatible one, it simplifies the API \n",
    "\n",
    "env_name = \"Multi-agent-2x2\"\n",
    "register_env(\n",
    "    env_name,\n",
    "    lambda _: parallel_petting_env\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(parallel_petting_env.action_space)\n",
    "print(parallel_petting_env.observation_space)\n",
    "print(parallel_petting_env.get_agent_ids())\n",
    "print(parallel_petting_env.action_space_sample())\n",
    "print(parallel_petting_env.get_sub_environments)\n",
    "\n",
    "parallel_petting_env.get_sub_environments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create algorithm config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray.tune.logger import pretty_print\n",
    "\n",
    "ppo_config = (\n",
    "    PPOConfig() # configuration class, initialising it returns an object self (config object)\n",
    "    .rollouts(num_rollout_workers=1)\n",
    "    .resources(num_gpus=0)\n",
    "    .environment(env_name, disable_env_checking=False)\n",
    "    .training(train_batch_size=4000)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = ppo_config.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo.get_policy().get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "tune.run(run_or_experiment='run', name=env_name, config=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = algo.train()\n",
    "pretty_print(result)\n",
    "\n",
    "checkpoint_dir = algo.save().checkpoint.path\n",
    "print(f\"Checkpoint saved in directory {checkpoint_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "ray.shutdown()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
